ğŸ“¦ Automated File Upload to Pinecone

ğŸ” Overview
This workflow automates the process of uploading files (like PDFs, text, or documents) to [Pinecone](https://www.pinecone.io/) for semantic search and vector storage. It parses the input, converts content into embeddings using an LLM/embedding API, and sends them to a Pinecone index.

âš™ï¸ Tools Used
- [n8n](https://n8n.io/) â€” for orchestration
- [Pinecone](https://www.pinecone.io/) â€” for vector storage
- Cohere â€” to generate embeddings 
- Google Drive â€” as input source 
- Recursive Character Text Splitter

---

ğŸ“ Files
- `workflow.json` â€” ready-to-import n8n workflow
- `architecture.png` â€” visual diagram of how the workflow works
- `nike-earnings.pdf` â€” example file used in testing

---

ğŸ”„ Workflow Steps

1. Trigger: A file is uploaded via Google Drive.
2. Extract: File is parsed using text extractor or PDF parser.
3. Embed: Text is converted into vector embeddings using an embedding API.
4. Chunk: Long documents are broken into chunks.
5. Upload to Pinecone: Each embedding is stored with metadata in Pinecone index.

---

ğŸ§  Why This Matters

- ğŸ“š Automates vectorizing document pipelines
- ğŸ§  Makes documents searchable via semantic queries
- âš¡ Eliminates manual upload + chunking

---

ğŸ’¡ What Youâ€™ll Learn

- How to connect and authenticate with Pinecone from n8n
- How to embed documents using OpenAI or Cohere APIs
- Efficient chunking strategies for large files
- Adding metadata to each embedding for advanced filtering

---

ğŸ“¸ Visual Flow

![Workflow Overview](architecture.png)

---

ğŸ”— Resources

- [Pinecone Docs](https://docs.pinecone.io/)
- [OpenAI Embedding API](https://platform.openai.com/docs/guides/embeddings)
- [n8n Docs](https://docs.n8n.io/)
- [LangChain Text Splitters](https://docs.langchain.com/docs/components/text-splitters/)

---

ğŸ‘¤ Author

**Anshika Sinha**  
Automation enthusiast | AI workflow builder  
[LinkedIn](https://linkedin.com/) â€¢ [GitHub](https://github.com/)

